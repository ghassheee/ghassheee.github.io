---
title: Linear Logic
date: 2017-01-01
layout: dep
comments: true
---

UNDER CONSTRUCTION



# resource comsumption

- "linear logic" consumes resources.
- "classical logic" never consumes propositions.

## classical logic

In classical logic, we do have a single $ A $ to say $ A \land A $ .

$ A \vdash A \land A $

## linear logic

But in Linear Logic, we must prepare 2 $ A $ s to say $ A \land A $.<br>
This is the comsumption of resources.

$ A, A \vdash A \land A $


# what is $ ( A ^ \bot ⊗ B ^ \bot ) ^ \bot $

In Linear Logic you can find some new notations.<br>
Let's start with knowing what ⅋ is.

- $ A ⅋ B : \equiv ( A ^ \bot \otimes B ^ \bot ) ^ \bot $
- $ A \& B : \equiv ( A ^ \bot \oplus B ^ \bot ) ^ \bot $



## Dual functor

First, let's find a functor $ ( ^ \bot ) : A \mapsto A ^ \bot $,<br>
it maps a category to the opposite category and vice versa.

### functor (z*)

Let's see some visible example. It is a good way to use 3D groups, which is represented by $ A _ 4 $ . <br>
$ A _ 4 $ consists of 12 elements which is generated by simply two 120-degree roatations, {a,b}. see [here](../math/2017-04-18-Automorphism.md/).

I also prepare an element $ z \in S _ 4 \backslash A _ 4 $. <br>
$ S _ 4 $ is exactly the group of a cube rotation of itself as $ A _ 4 $ that of tetrahedron,<br>
and $ S _ 4 $ consists of 24 elements which includes the whole $ A _ 4 $ .

To get visiblity, we give a typical representation of these groups.<br>
And does this (z*) make sense for the functor we seek for?

~~~
λ> a
0      0       1
1      0       0
0      1       0

λ> b
0      0       1
-1     0       0
0      -1      0

λ> z
0      0       -1
0      -1      0
-1     0       0

λ> z*a
0      -1      0
-1     0       0
0      0       -1

λ> z*b
0      1       0
1      0       0
0      0       -1

λ> a*b
0      -1      0
0      0       1
-1     0       0

λ> z*((z*a)*(z*b))
0      0       -1
0      1       0
1      0       0
~~~


where `z` is exactly a 180 degree rotation in $ S _ 4 \backslash A _ 4 $,
which means `(z*(z* a )) = a` . <br>

In this case, the elements of $ ( A ^ \bot \otimes B ^ \bot ) ^ \bot $ locates in $ S _ 4 \backslash A _ 4 $ , whereas that of $ A \otimes B $ in $ A _ 4 $ .

Because we seek for a functor `F` to the opposite category, it should satisfy the law;
~~~
F( F(a)) = a
F(a * b) = F(b) * F(a)
~~~

but `(z*(a*b))`  $ \neq $  `(z*b)*(z*a)`.


note that it can be a group in a bad way.
~~~
a' * b' := a' * (z * b')
~~~




### functor `ι(z)`

How about ι(z) ?

`ι(m)` is a transformation, taking `g` as an argument, which is
"the operation `g` were done in another place far by `m` from current position ".


`ι(m)(g) :=   m * g * m` $ {} ^ {-1} $


In this example, `m * m = id ` or ` m = m` $ {} ^ {-1} $ ,

~~~
ι(m)(a) = m * a * m
ι(m)(ι(m)(a) * ι(m)(b)) = m*((m*a*m)*(m*b*m))*m = (m*m)*a*(m*m)*b*(m*m) = a*b`
~~~

There is no difference between `ι(m)( ι(m)(a) * ι(m)(b) )` and `a * b` .
So, with this construction, $ ( A ^ \bot \otimes B ^ \bot ) ^ \bot \equiv A \otimes B $ makes no difference visibly.
We have to find another Functor F, which maps a category into the opposite category.


### to the higher dimension (transpose)

Since the above example fails, let me think of rotations in higher dimensions than 3D.
In 4D or higher space we might be able to construct another Functor which maps a category to the opposite category. e.g. you can think a lens space which consists of two spheres. we paste the surface of one sphere to the another.
The functor maps points outside of the combined sphere to the inside of the sphere, "inside-out" the sphere.

Here we choose `*` as a tensor product, which is not commutative.
So, I hope, we might find a functor. Now I am focusing on 4D space.

In complex plain, a map $ z \mapsto \frac{1}{z} $ is an inside-out functor.
So, I want to know an example of its 3-dimensional version.

Yay !!
if we define `F := transpose` it satisfies the all conditions we want!!
( As, you know, it is obvious from $ (A B) ^ T = B ^ T A ^ T $ . Rather, see them as a 120-degree rotations. )

~~~
λ> t = transpose
λ> t a
0      1       0
0      0       1
1      0       0

λ> a
0      0       1
1      0       0
0      1       0

λ> t ((t a)*(t b))
0      1       0
0      0       -1
-1     0       0

λ> b * a
0      1       0
0      0       -1
-1     0       0
~~~

Thus
`b * a = t((t a) * (t b))`
and so
`a * b != t((t a) * (t b))` !!

This is what $ ( G ^ \bot \otimes G ^ \bot ) ^ \bot $ means.


This describes that `transpose` is inside-out the sphere, or it converts `left handed space` into `right handed space`.

But still we have one problem, is `*` a tensor product ?


## Tensor

Here G denotes Z[G], a group ring. But forget the ring,<br>
it is not important to think about coefficients.

Now we cannot say that `G` is a tensor product `G⊗G`. <br>
Because I cannot give it the universality. (Indeed, it may not be.)<br>
But the example I showed above is very meaningful.
let me explain it here.

Tensor product is $ \otimes : G \times G \to G \otimes G $, <br>
( more generally $ \otimes : A \times B \to A \otimes B $ ) satisfying the universality;

Tensor's universality means that <br>
forall $ \phi : G \times G \to G $, there exists a unique map $ p : G \otimes G \to G $ which is homomorphic and they satisfy a diagram $ \phi = p \circ \otimes $ .
so even if $ G $ is not the tensor product,
it is sufficient to say the above argument to show $ G \otimes G $ is not the same with $ ( G ^ \bot \otimes G ^ \bot ) ^ \bot $

In the above example,<br>
For `*` there is a unique morphism $ p $ and `*` must satisfy;

`*` $ = p \circ \otimes $

We showed that
$ G ( p \circ \otimes ) G $ is not the same with $ ( G ^ \bot ( p \circ \otimes ) G ^ \bot ) ^ \bot $. <br>
Hence $ G \otimes G $ is not the same with $ ( G ^ \bot \otimes G ^ \bot ) ^ \bot $ . $ \Box $


## conclusion

If we follow the definition of "Opposite Category",
we will find that the category is exactly the `inside-out` of a category.
With the above examples we can connect these inside-out of category with inside-out of elements.
That's why nlab says "it is something like plus and minus", I concluded.

$ \mathbb{Z} $ itself is a symmetric monoidal category but `-1` is not `+1`.<br>
This is what I showed without minus operator and with matrices and `transpose`.


<br>

※ Special Thanks to @equivrel !




# exponentials (UNDER CONSTRUCTION)



- $ ! A $
- $ ? A $



# `Linear Logic `cannot` change blockchain in the way of the paper` ?

If yes,
please explain how and why isolated concurrent threads and related concurrent threads having effects on each other are inside-out, or symmetric reversed?

They must be exactly `symmetric`.

Linear Logic is a logic which will be built on the quantum logic, I believe strongly.<br>
But the author wants to tell about resource comsumption.<br>
We need to define or find another kind of logic to be smarter.




# Linear Logic (JUST QUOTING nlab)


NOTICE : The Beneath text is just
from [nlab](https://ncatlab.org/nlab/show/linear+logic)

UNDER CONSTRUCTION of my interpretation


<style>
.red {color: red;}
</style>

## idea

Linear logic is sometimes thought of as being a logic for <text class="red">arguing about resource sensitive issues</text>, but it can also be thought of categorically, or interpreted using Game Semantics,
or as being related to <text class="red">"Petri nets"</text>, or as a particular form of quantum logic. A bit more formally:

Linear logic is a substructural logic in which

- the <text class="red">contraction rule</text> and
- the <text class="red">weakening rule</text>

are omitted, or at least have their applicability restricted.

In the original definition of (Girard 87),
linear logic is the internal logic of/has categorical semantics in star-autonomous categories (Seely 89, prop. 1.5).

But more generally linear logic came to refer to the internal logic of any possibly-non-cartesian symmetric closed monoidal category (then usually called multiplicative intuitionistic linear logic – MILL) or even polycategory (Szabo 78 see the history section and see also de Paiva 89, Blute 91, Benton-Bierman-de Paiva-Hyland 92, Hyland-de Paiva 93, Bierman 95, Barber 97, Schalk 04, Melliès 09). Under this interpretation, proof nets (or the associated Kelly-Mac Lane graphs) of linear logic are similar to string diagrams for monoidal categories.

Indeed, these more general senses of linear logic still faithfully follow the original motivation for the term “linear” as connoting “resource availability” explained below (and in Girard 87), since the non-cartesianness of the tensor product means the absence of a diagonal map and hence the impossibility of functions to depend on more than a single (linear) copy of their variables.

In addition to these usual “denotational” categorical semantics, linear logic also has an “operational” categorical semantics, called the Geometry of Interaction, in traced monoidal categories.

Although linear logic is traditionally presented in terms of inference rules, it was apparently discovered by Girard while studying coherent spaces.



## Quantum logic

Linear logic and linear type theory can be argued to be the proper incarnation of quantum logic (see there for references). In this context the linearity of the logic, hence the absence of diagonal maps in its categorical semantics (in non-cartesian symmetric monoidal categories) reflects the no-cloning theorem of quantum physics.


## Game semantics

Linear logic can also be interpreted using a semantics of “games” or “interactions”. Under this interpretation, each proposition in a sequent represents a game being played or a transaction protocol being executed. An assertion of, for instance,

P,Q ⊢ R
$ P, Q \vdash R $

means roughly that if I am playing three simultaneous games of P P, Q Q, and R R, in which I am the left player in P P and Q Q and the right player in R R, then I have a strategy which will enable me to win at least one of them. Now the above statements about “resources” translate into saying that I have to play in all the games I am given and can’t invent new ones on the fly.

## As a relevant logic

Linear logic is closely related to notions of relevant logic, which have been studied for much longer. The goal of relevant logic is to disallow statements like “if pigs can fly, then grass is green” which are true, under the usual logical interpretation of implication, but in which the hypothesis has nothing to do with the conclusion. Clearly there is a relationship with the “resource semantics”: if we want to require that all hypotheses are “used” in a proof then we need to disallow weakening.
